{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests Solution\n",
    "Random Forests are an ensemble of multiple decision trees\n",
    "\n",
    "There are a few libraries we'll need - numpy and pandas for handling the data, and a few modules from SciKit Learn:\n",
    "* Datasets - has the IRIS dataset for us to use, ready for consumption\n",
    "* Ensemble - this holds the functionality for any ensemble model, including Random Forests\n",
    "* Model Selection - this helps us split our dataset down to training and validation sets\n",
    "* Metrics - this has the fucntionality for us to monitor our model and see how it behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, ensemble, model_selection, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to load the data from the sklearn `datasets` module, and load it into a dataframe for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "iris_dataframe=pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
    "\n",
    "iris_dataframe[\"label\"] = pd.Categorical.from_codes(iris_dataset.target, iris_dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "    label  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and test datasets\n",
    "Let's look at the attributes - the \"x\" data - separate from the labels (\"y\").\n",
    "\n",
    "This comes from the idea that any model is a simple function where \n",
    "$$answers = AI\\ model(attributes)$$\n",
    "or more simply\n",
    "$$y = f(x)$$\n",
    "\n",
    "We need to do a few things:\n",
    "1. Create an X and Y set\n",
    "2. Factorise Y - at the moment the labels are strings, which are hard to understand for the algorithm. We need to change them to integers (e.g. 0, 1, 2 for the three different species of iris flower)\n",
    "3. Split the dataset into training and validation sets so don't test the model on examples it has seen already\n",
    "\n",
    "#### Hints\n",
    "```python\n",
    "pd.factorise(labels)[0] #factorises classes into integers\n",
    "model_selection.train_test_split # creates x train, x test, y train and y test outputs in that order. needs x, y and a decimal test size. split it by 30%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "Once the data is ready, we need to create a model to train. We are going to be creating an \"instance\" of the Random Forests sklearn class - this may be a little different to the basic python you are used to so far. Effectively, you are creating a already-made copy of a random forests model based on a blueprint that sklearn provides, complete with special functions.\n",
    "\n",
    "the RandomForestClassifier needs to know how many cores it is allowed to run on. -1 cores means use all available cores.\n",
    "\n",
    "We then need to train the model on the training data, both x and y. In this case, the term for training is \"fitting\". Once it's been trained/fitted, we ask it to predict the answers for validation dataset, given x. importantly, the model does not change itself when predicting. It just tried to label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ensemble.RandomForestClassifier(n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "```python\n",
    "classifier.fit #takes X and y\n",
    "classifier.predict # takes X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Performance\n",
    "When we run our model, it is helpful to capture the output as a variable. We can then pass that forward with out metrics, which are made easy with the sklearn metrics module.\n",
    "\n",
    "#### Hints\n",
    "```python\n",
    "output = classifier.predict(...)\n",
    "metrics.accuracy_score(...) # takes validation y and the predictions\n",
    "metrics.f1_score(...) # same again. also needs a specified average - use \"weighted\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "F1: 0.931135531135531\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"F1:\",metrics.f1_score(y_test, predictions, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at two more exotic ways of measuring the performance. A confusion metrix that shows how likely the classes are mistaken for each other. Sklearn also can estimate how important each feature or attrivute was for the classification - a great way to understand your model and also look for overdependence on a single feature.\n",
    "\n",
    "#### Hints\n",
    "check out pandas' crosstab function, and use the y_test and predictions against each other.\n",
    "\n",
    "Our classifier instance has a `.feature_importances_` attribute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
